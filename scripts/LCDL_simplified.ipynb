{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T22:17:41.413142Z"
    },
    "id": "VtkbiY_G3SNh"
   },
   "source": [
    "# dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T01:58:46.029260Z",
     "start_time": "2024-02-11T01:58:46.023926Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')  # Adjust the path as necessary\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T01:58:46.489717Z",
     "start_time": "2024-02-11T01:58:46.484187Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T01:58:51.219876Z",
     "start_time": "2024-02-11T01:58:47.011565Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4kXa3G0ayvu",
    "outputId": "14262c14-c74b-4ab8-fae5-84a6d9b1dc14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 09:10:49.331261: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from inverse_canopy import InverseCanopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vwAAjKk52L6"
   },
   "source": [
    "# **Model Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tunable initialized: dtype=<dtype: 'float64'>, epsilon=1e-30\n",
      "learning_rate: 0.1,patience: 50,min_improvement: 0.001,max_steps: 5000,seed: 372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 09:10:52.308568: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: AMD Radeon Pro 5500M\n",
      "2024-02-11 09:10:52.308594: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-02-11 09:10:52.308601: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 3.99 GB\n",
      "2024-02-11 09:10:52.308642: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-11 09:10:52.308675: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-02-11 09:10:52.403279: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation ReadVariableOp: Could not satisfy explicit device specification '' because the node {{colocation_node ReadVariableOp}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssignVariableOp: GPU CPU \nAssignSubVariableOp: CPU \nIdentity: GPU CPU \nReadVariableOp: GPU CPU \n_Arg: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  ReadVariableOp (ReadVariableOp) \n  Adam/AssignSubVariableOp (AssignSubVariableOp) \n  ReadVariableOp_2 (ReadVariableOp) \n  AssignVariableOp (AssignVariableOp) \n  Func/StatefulPartitionedCall/input/_0 (Identity) \n  Func/PartitionedCall_1/input/_53 (Identity) \n  Func/StatefulPartitionedCall/StatefulPartitionedCall/input/_66 (Identity) \n  Func/PartitionedCall_1/PartitionedCall/input/_125 (Identity) \n  Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/input/_138 (Identity) \n  Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/output/_146 (Identity) \n\n\t [[{{node ReadVariableOp}}]] [Op:__inference_optimization_step_1133]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 56\u001B[0m\n\u001B[1;32m     32\u001B[0m end_states \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLCDL-1\u001B[39m\u001B[38;5;124m'\u001B[39m: {\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msequence\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     52\u001B[0m     },\n\u001B[1;32m     53\u001B[0m }\n\u001B[1;32m     55\u001B[0m model \u001B[38;5;241m=\u001B[39m InverseCanopy(conditional_events, end_states, tunable)\n\u001B[0;32m---> 56\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtunable\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_steps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtunable\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpatience\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtunable\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlearning_rate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m model\u001B[38;5;241m.\u001B[39msummarize(show_plot\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, show_metrics\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/Projects/inverse-canopy/scripts/../inverse_canopy/inverse_canopy.py:341\u001B[0m, in \u001B[0;36mInverseCanopy.fit\u001B[0;34m(self, learning_rate, patience, min_improvement, steps, seed)\u001B[0m\n\u001B[1;32m    339\u001B[0m early_stop \u001B[38;5;241m=\u001B[39m EarlyStop(min_delta\u001B[38;5;241m=\u001B[39mmin_improvement, patience\u001B[38;5;241m=\u001B[39mpatience)\n\u001B[1;32m    340\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate, amsgrad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, epsilon\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepsilon)\n\u001B[0;32m--> 341\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/inverse-canopy/scripts/../inverse_canopy/inverse_canopy.py:350\u001B[0m, in \u001B[0;36mInverseCanopy.train_model\u001B[0;34m(self, optimizer, early_stop, steps)\u001B[0m\n\u001B[1;32m    347\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(steps):\n\u001B[0;32m--> 350\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimization_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    352\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    353\u001B[0m         elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time  \u001B[38;5;66;03m# Calculate elapsed time\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/inverse-canopy/venv-3p10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Projects/inverse-canopy/venv-3p10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Cannot assign a device for operation ReadVariableOp: Could not satisfy explicit device specification '' because the node {{colocation_node ReadVariableOp}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssignVariableOp: GPU CPU \nAssignSubVariableOp: CPU \nIdentity: GPU CPU \nReadVariableOp: GPU CPU \n_Arg: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  ReadVariableOp (ReadVariableOp) \n  Adam/AssignSubVariableOp (AssignSubVariableOp) \n  ReadVariableOp_2 (ReadVariableOp) \n  AssignVariableOp (AssignVariableOp) \n  Func/StatefulPartitionedCall/input/_0 (Identity) \n  Func/PartitionedCall_1/input/_53 (Identity) \n  Func/StatefulPartitionedCall/StatefulPartitionedCall/input/_66 (Identity) \n  Func/PartitionedCall_1/PartitionedCall/input/_125 (Identity) \n  Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/input/_138 (Identity) \n  Func/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/output/_146 (Identity) \n\n\t [[{{node ReadVariableOp}}]] [Op:__inference_optimization_step_1133]"
     ]
    }
   ],
   "source": [
    "from inverse_canopy import InverseCanopy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tunable = {\n",
    " 'num_samples': 100,      # number of monte carlo samples\n",
    " 'learning_rate': 0.1,    # the gradient update rate\n",
    " 'dtype': tf.float64,     # use 64-bit floats\n",
    " 'epsilon': 1e-30,        # useful for avoiding log(0 + epsilon) type errors\n",
    " 'max_steps': 5000,       # maximum steps, regardless of convergence\n",
    " 'patience': 50,          # number of steps to wait before early stopping if the loss does not improve   \n",
    "}\n",
    "\n",
    "conditional_events = {\n",
    "    'names': ['LCDL', 'PKRU', 'DHRS', 'DHRL'],\n",
    "    'bounds': {\n",
    "        'mean': {\n",
    "            'min': 1e-14,\n",
    "            'max': 1.00,\n",
    "        },\n",
    "        'std': {\n",
    "            'min': 1e-10,\n",
    "            'max': 1e8,\n",
    "        },\n",
    "     },\n",
    "    'initial': {\n",
    "       'mean': 5e-1,\n",
    "       'std': 1e8,\n",
    "    }\n",
    "}\n",
    "\n",
    "end_states = {\n",
    "    'LCDL-1': {\n",
    "        'sequence': [1, 0, 0, 0],\n",
    "        'probability': 1.1e-8,\n",
    "    },\n",
    "    'LCDL-2': {\n",
    "        'sequence': [1, 0, 0, 1],\n",
    "        'probability': 1.00e-11,\n",
    "    },\n",
    "    'LCDL-3': {\n",
    "        'sequence': [1, 0, 1, np.nan],\n",
    "        'probability': 1.00e-11,\n",
    "    },\n",
    "    'LCDL-4': {\n",
    "        'sequence': [1, 1, np.nan, np.nan],\n",
    "        'probability': 1.00e-11,\n",
    "    },\n",
    "    'LCDL-0': {\n",
    "        'sequence': [0, np.nan, np.nan, np.nan],\n",
    "        'probability': 1.0 - 1.1e-8 - 1.00e-11 - 1.00e-11 - 1.00e-11, # one minus all the other end-states\n",
    "    },\n",
    "}\n",
    "\n",
    "model = InverseCanopy(conditional_events, end_states, tunable)\n",
    "model.fit(steps=tunable['max_steps'], patience=tunable['patience'], learning_rate=tunable['learning_rate'])\n",
    "model.summarize(show_plot=True, show_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tunable = {\n",
    " 'num_samples': 1000,     # number of monte carlo samples\n",
    " 'learning_rate': 0.1,    # the gradient update rate\n",
    " 'dtype': tf.float64,     # use 64-bit floats\n",
    " 'epsilon': 1e-30,        # useful for avoiding log(0 + epsilon) type errors\n",
    " 'max_steps': 5000,       # maximum steps, regardless of convergence\n",
    " 'patience': 50,          # number of steps to wait before stopping, if the loss does not improve\n",
    "}\n",
    "\n",
    "conditional_events = {\n",
    "    'names': ['SDFR      ', 'LMFD      ', 'RFIR      ', 'LLRF      ', 'SSSD|~LLRF', 'SSSD|LLRF ', 'SYSO|~LLRF', 'SYSO|LLRF '],  # Assuming names based on the sequences\n",
    "    'bounds': {\n",
    "        'mean': {\n",
    "            'min': 1e-14,\n",
    "            'max': 1.00,\n",
    "        },\n",
    "        'std': {\n",
    "            'min': 1e-10,\n",
    "            'max': 1e8,\n",
    "        },\n",
    "     },\n",
    "    'initial': {\n",
    "       'mean': 5e-1,\n",
    "       'std': 1e8,\n",
    "    }\n",
    "}\n",
    "\n",
    "end_states = {\n",
    "    'SDFR-0': {\n",
    "        'sequence': [0, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "        'probability': 1 - 4.2e-3 - 4.2e-5 - 5.8e-9 - 2.1e-5 - 1.9e-5 - 2.1e-6 - 1.7e-8 - 4.3e-9,\n",
    "    },\n",
    "    'SDFR-1': {\n",
    "        'sequence': [1, 0, 0, 0, 0, np.nan, np.nan, np.nan],\n",
    "        'probability': 4.2e-3,\n",
    "    },\n",
    "    'SDFR-2': {\n",
    "        'sequence': [1, 0, 0, 0, 1, np.nan, 0, np.nan]  ,\n",
    "        'probability': 4.2e-5,\n",
    "    },\n",
    "    'SDFR-3': {\n",
    "        'sequence': [1, 0, 0, 0, 1, np.nan, 1, np.nan],\n",
    "        'probability': 5.8e-9,\n",
    "    },\n",
    "    'SDFR-4': {\n",
    "        'sequence': [1, 0, 0, 1, np.nan, 0, np.nan, np.nan],\n",
    "        'probability': 2.1e-5,\n",
    "    },\n",
    "    'SDFR-5': {\n",
    "        'sequence': [1, 0, 0, 1, np.nan, 1, np.nan, 0],\n",
    "        'probability': 1.9e-5,\n",
    "    },\n",
    "    'SDFR-6': {\n",
    "        'sequence': [1, 0, 0, 1, np.nan, 1, np.nan, 1],\n",
    "        'probability': 2.1e-6,\n",
    "    },\n",
    "    'SDFR-7': {\n",
    "        'sequence': [1, 0, 1, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "        'probability': 1.7e-8,  \n",
    "    },\n",
    "    'SDFR-8': {\n",
    "        'sequence': [1, 1, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "        'probability': 4.3e-9,  \n",
    "    },\n",
    "}\n",
    "\n",
    "model = InverseCanopy(conditional_events, end_states, tunable)\n",
    "model.fit(steps=tunable['max_steps'], patience=tunable['patience'], learning_rate=tunable['learning_rate'])\n",
    "model.summarize(show_plot=True, show_metrics=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "33M-ijkwzA6S",
    "xsqjmoGTLQEv",
    "duRupGgoVhyz"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
